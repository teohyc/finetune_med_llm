{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.30557677616501144,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010185892538833716,
      "grad_norm": 0.824479877948761,
      "learning_rate": 9e-05,
      "loss": 2.5781,
      "step": 10
    },
    {
      "epoch": 0.02037178507766743,
      "grad_norm": 1.5584944486618042,
      "learning_rate": 9.97625431384671e-05,
      "loss": 2.0943,
      "step": 20
    },
    {
      "epoch": 0.030557677616501147,
      "grad_norm": 1.5168718099594116,
      "learning_rate": 9.894459981780711e-05,
      "loss": 1.3922,
      "step": 30
    },
    {
      "epoch": 0.04074357015533486,
      "grad_norm": 1.1603829860687256,
      "learning_rate": 9.755282581475769e-05,
      "loss": 1.1055,
      "step": 40
    },
    {
      "epoch": 0.05092946269416858,
      "grad_norm": 1.4490039348602295,
      "learning_rate": 9.56035384069935e-05,
      "loss": 0.883,
      "step": 50
    },
    {
      "epoch": 0.061115355233002294,
      "grad_norm": 1.4044053554534912,
      "learning_rate": 9.31195912071201e-05,
      "loss": 0.9278,
      "step": 60
    },
    {
      "epoch": 0.07130124777183601,
      "grad_norm": 1.2380269765853882,
      "learning_rate": 9.013010622496144e-05,
      "loss": 0.828,
      "step": 70
    },
    {
      "epoch": 0.08148714031066973,
      "grad_norm": 1.076514720916748,
      "learning_rate": 8.667013243862113e-05,
      "loss": 0.6894,
      "step": 80
    },
    {
      "epoch": 0.09167303284950344,
      "grad_norm": 1.1760973930358887,
      "learning_rate": 8.278023487725982e-05,
      "loss": 0.8316,
      "step": 90
    },
    {
      "epoch": 0.10185892538833716,
      "grad_norm": 1.149254560470581,
      "learning_rate": 7.850601903321716e-05,
      "loss": 0.7569,
      "step": 100
    },
    {
      "epoch": 0.11204481792717087,
      "grad_norm": 1.2048916816711426,
      "learning_rate": 7.389759617931182e-05,
      "loss": 0.7045,
      "step": 110
    },
    {
      "epoch": 0.12223071046600459,
      "grad_norm": 1.1696826219558716,
      "learning_rate": 6.90089958599846e-05,
      "loss": 0.7863,
      "step": 120
    },
    {
      "epoch": 0.1324166030048383,
      "grad_norm": 1.208368182182312,
      "learning_rate": 6.389753244428972e-05,
      "loss": 0.717,
      "step": 130
    },
    {
      "epoch": 0.14260249554367202,
      "grad_norm": 1.3437870740890503,
      "learning_rate": 5.862313316732063e-05,
      "loss": 0.7745,
      "step": 140
    },
    {
      "epoch": 0.15278838808250572,
      "grad_norm": 1.5886600017547607,
      "learning_rate": 5.324763553817054e-05,
      "loss": 0.7794,
      "step": 150
    },
    {
      "epoch": 0.16297428062133945,
      "grad_norm": 1.21317458152771,
      "learning_rate": 4.78340623516769e-05,
      "loss": 0.7978,
      "step": 160
    },
    {
      "epoch": 0.17316017316017315,
      "grad_norm": 1.4368274211883545,
      "learning_rate": 4.244588280377417e-05,
      "loss": 0.785,
      "step": 170
    },
    {
      "epoch": 0.18334606569900688,
      "grad_norm": 1.3650081157684326,
      "learning_rate": 3.714626837320195e-05,
      "loss": 0.7461,
      "step": 180
    },
    {
      "epoch": 0.19353195823784058,
      "grad_norm": 1.2151068449020386,
      "learning_rate": 3.199735219367507e-05,
      "loss": 0.7152,
      "step": 190
    },
    {
      "epoch": 0.20371785077667431,
      "grad_norm": 1.4358726739883423,
      "learning_rate": 2.7059500599699476e-05,
      "loss": 0.7915,
      "step": 200
    },
    {
      "epoch": 0.21390374331550802,
      "grad_norm": 1.4734680652618408,
      "learning_rate": 2.2390605386493757e-05,
      "loss": 0.732,
      "step": 210
    },
    {
      "epoch": 0.22408963585434175,
      "grad_norm": 1.273937702178955,
      "learning_rate": 1.8045405081621215e-05,
      "loss": 0.6645,
      "step": 220
    },
    {
      "epoch": 0.23427552839317545,
      "grad_norm": 1.4130690097808838,
      "learning_rate": 1.4074843185801883e-05,
      "loss": 0.664,
      "step": 230
    },
    {
      "epoch": 0.24446142093200918,
      "grad_norm": 1.3573600053787231,
      "learning_rate": 1.0525470906944918e-05,
      "loss": 0.7099,
      "step": 240
    },
    {
      "epoch": 0.2546473134708429,
      "grad_norm": 1.663517713546753,
      "learning_rate": 7.438901389797881e-06,
      "loss": 0.8262,
      "step": 250
    },
    {
      "epoch": 0.2648332060096766,
      "grad_norm": 1.5099620819091797,
      "learning_rate": 4.851321839871908e-06,
      "loss": 0.624,
      "step": 260
    },
    {
      "epoch": 0.2750190985485103,
      "grad_norm": 1.2190508842468262,
      "learning_rate": 2.793069261543335e-06,
      "loss": 0.6926,
      "step": 270
    },
    {
      "epoch": 0.28520499108734404,
      "grad_norm": 1.6866379976272583,
      "learning_rate": 1.288274784414789e-06,
      "loss": 0.7426,
      "step": 280
    },
    {
      "epoch": 0.29539088362617777,
      "grad_norm": 1.57808256149292,
      "learning_rate": 3.5458074788387586e-07,
      "loss": 0.7088,
      "step": 290
    },
    {
      "epoch": 0.30557677616501144,
      "grad_norm": 1.6392320394515991,
      "learning_rate": 2.9338608443452154e-09,
      "loss": 0.6879,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2921558733588480.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
